{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Petbreed Multiclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try out the working classifier [here](https://mypetbreed.onrender.com/) as a web app!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import *\n",
    "import pretrainedmodels\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.tracker import SaveModelCallback\n",
    "from fastai.vision.models import *\n",
    "from fastai.vision.learner import model_meta\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU#0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "print(f'Using GPU#{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll configure our path's and setup some parameters we'll be changing throughout the training process to scale the model with increasing image resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "TRAIN = PATH/'train'\n",
    "TEST = PATH/'test'\n",
    "LARGE = PATH/'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"resnet50_v2_\"\n",
    "# model = models.resnet50\n",
    "\n",
    "# prefix = \"vgg19_bn_\"\n",
    "# model = models.vgg19_bn\n",
    "\n",
    "prefix = \"resnet152_\"\n",
    "model = models.resnet152\n",
    "\n",
    "# prefix = \"xception_\"\n",
    "\n",
    "# def xception(pretrained=False):\n",
    "#     pretrained = 'imagenet' if pretrained else None\n",
    "#     model = pretrainedmodels.xception(pretrained=pretrained)\n",
    "#     return nn.Sequential(*list(model.children()))\n",
    "\n",
    "# model = xception\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything, we need to prepare our data for modeling. With how the raw files are structured, the steps we'll need to take are:\n",
    "\n",
    "1. Match image files to breed names. Since the file names are just numbers and the breed names are IDs in a csv, we need to make a function that pairs the two together for when we setup our [Databunch](https://docs.fast.ai/data_block.html).\n",
    "2. Upsample imageset. Since we're limited to train with only a few thousand images in total, our training and validation accuracy should increase if we have more data to train with. Because of this, we can duplicate our training set several times to \"artificially\" get a bigger dataset. We'll avoid overfitting by appying unique image transforms to all these images so that each image is different than the rest, increasing the generalization of our model.\n",
    "3. Create a databunch. Using Fastai's Datablock API, we'll create a databunch that uses our labeling function and upsampled dataset to split our training dataset into training and validation subsets. We'll also apply image transforms using Fastai's `vision.transform` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breedID</th>\n",
       "      <th>speciesID</th>\n",
       "      <th>fname</th>\n",
       "      <th>breed_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>newfoundland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>staffordshire bull terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>keeshond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>american bulldog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>saint bernard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breedID  speciesID  fname                  breed_name\n",
       "0       23          2      0                newfoundland\n",
       "1       35          2      1  staffordshire bull terrier\n",
       "2       19          2      2                    keeshond\n",
       "3        2          2      3            american bulldog\n",
       "4       29          2      4               saint bernard"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(PATH/'train.csv', engine='python')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets cycle through our Training set 10 times to generate a bigger dataset (only do this 1 time!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt = os.listdir(TRAIN)\n",
    "amt_len = len(amt)\n",
    "mult_amt = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i = 1\n",
    "# while i < mult_amt:\n",
    "#     n = 0\n",
    "#     while n < amt_len:\n",
    "#         amt.append(amt[n][:-4] + '_copy_' + str(i) + '.jpg')\n",
    "#         os.system(f'cp {TRAIN}/{amt[n]} {LARGE}/{amt[n][:-4]}_copy_{str(i)}.jpg')\n",
    "#         n+=1\n",
    "#         if n%250 == 0:\n",
    "#             print(n)\n",
    "#     i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom label function for the englarged dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_labels(fname):\n",
    "    fname = str(fname) # Convert path object to string\n",
    "    fname = fname.split(sep='/')\n",
    "    \n",
    "    fname = fname[len(fname) - 1]\n",
    "    fname = fname[:-11]\n",
    "\n",
    "    row = train_df.loc[train_df['fname'] == int(fname)]\n",
    "    label = row[\"breed_name\"].values[0]\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/valid split proportional to class amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_train_valid_split(mult_amt, val_pct):\n",
    "    breeds = list(train_df.breed_name.unique())\n",
    "    \n",
    "    for breed in breeds:\n",
    "        breed_df = train_df.loc[train_df[\"breed_name\"] == str(breed)]\n",
    "        breed_df = shuffle(breed_df, random_state=42)\n",
    "        fnames = list(breed_df[\"fname\"])\n",
    "        f_amt = round(len(fnames)*val_pct)\n",
    "        \n",
    "        # Validation split\n",
    "        for file in fnames[0:f_amt]:            \n",
    "            for rep in range(1,mult_amt):\n",
    "                os.system(f\"mv {LARGE}/{file}_copy_{rep}.jpg {LARGE}/valid\")\n",
    "        print(f\"Completed {breed} validation split.\")\n",
    "    \n",
    "    # Training split\n",
    "    print(\"Starting training split.\")\n",
    "    os.system(f\"mv {LARGE}/*.jpg {LARGE}/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_train_valid_split(10, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datablock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is our labeling function for matching image file names with breed ids. We will input this into our databunch when we create it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling function used by Datablock API\n",
    "def get_labels(fname):    \n",
    "    fname = str(fname) # Convert path object to string\n",
    "    fname = fname.split(sep='/')\n",
    "    \n",
    "    fname = fname[len(fname) - 1]\n",
    "    fname = fname[:-4]\n",
    "\n",
    "    row = train_df.loc[train_df['fname'] == int(fname)]\n",
    "    label = row[\"breed_name\"].values[0]\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transforms List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "prob = 1\n",
    "brightness_range = (0.25,0.75)\n",
    "contrast_range = (0.5,1.5)\n",
    "jitter_mag = (0.005,0.01)\n",
    "max_warp = (0.3)\n",
    "rotate_range = (0,25)\n",
    "zoom_range = (1., 1.5)\n",
    "img_size = (128,512)\n",
    "x_pct = (0.25,0.75)\n",
    "y_pct = (0.25,0.75)\n",
    "\n",
    "# Transforms\n",
    "trn_tfms = [\n",
    "    brightness(change=brightness_range, use_on_y=False),\n",
    "    contrast(scale=contrast_range, use_on_y=False),\n",
    "    crop_pad(size=img_size, row_pct=x_pct, col_pct=y_pct, use_on_y=False), # Random Expand \n",
    "    flip_lr(p=prob, use_on_y=False), # Flips Image\n",
    "    jitter(magnitude=jitter_mag, use_on_y=False),\n",
    "    perspective_warp(magnitude=(-max_warp,max_warp), use_on_y=False),\n",
    "    rand_zoom(scale=zoom_range),\n",
    "    rotate(degrees=rotate_range, use_on_y=False)\n",
    "]\n",
    "\n",
    "val_tfms = [crop_pad(use_on_y=False)] \n",
    "tfms = (trn_tfms, val_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datablock\n",
    "def get_data(sz, bs):\n",
    "    data = (ImageList.from_folder(COMBINED_TRAIN)\n",
    "            .split_by_rand_pct(valid_pct=0.1, seed=42)\n",
    "            .label_from_func(get_labels) \n",
    "            .transform(tfms, size=sz)\n",
    "            .databunch(bs=bs).normalize(imagenet_stats))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Datablock for large dataset\n",
    "# def get_data(sz, bs):\n",
    "#     data = (ImageList.from_folder(LARGE) \n",
    "#             .split_by_folder()\n",
    "#             .label_from_func(get_large_labels) \n",
    "#             .transform(tfms, size=sz)\n",
    "#             .databunch(bs=bs).normalize(imagenet_stats))\n",
    "    \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = get_data(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully creating our databunch, let's look at some animals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our databunch is setup, its time to do some modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From testing various pretrained models and architechures out on the Azure VM, we saw best results with using a resnet50 architecture in a Convolutional Nerual Network. InceptionV3 wasnt getting nearly as good accuracy as Resnet50 (or Resnet34) and Vgg wasn't either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our learner class and load in some metrics we care about (error rate and accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception\n",
    "learn = cnn_learner(data, model, pretrained=True, cut=-1,\n",
    "                    split_on=lambda m: (m[0][11], m[1]), metrics=(error_rate,accuracy))\n",
    "\n",
    "# fastai/pytorch models\n",
    "# learn = cnn_learner(data, model, metrics=(error_rate,accuracy))\n",
    "\n",
    "\n",
    "learn.callbacks = [SaveModelCallback(learn, every='improvement', monitor='accuracy', name=f'{prefix}best', mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionV4 test\n",
    "def inceptionv4(pretrained=False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.inceptionv4(pretrained=pretrained)\n",
    "    all_layers = list(model.children())\n",
    "    return nn.Sequential(*all_layers[0], *all_layers[1:])\n",
    "\n",
    "learn = create_cnn(data, inceptionv4, pretrained=True,\n",
    "                   cut=-2, split_on=lambda m: (m[0][11], m[1]), metrics=(error_rate,accuracy))\n",
    "\n",
    "learn.callbacks = [SaveModelCallback(learn, every='improvement', monitor='accuracy', name=f'{prefix}best', mode='max')]\n",
    "\n",
    "prefix = \"inceptionv4_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNAS test\n",
    "def identity(x): return x\n",
    "\n",
    "def pnasnet5large(pretrained=False):    \n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.pnasnet5large(pretrained=pretrained, num_classes=1000) \n",
    "    model.logits = identity\n",
    "    return nn.Sequential(model)\n",
    "\n",
    "# model_meta[pnasnet5large] =  { 'cut': None, \n",
    "#                                'split': lambda m: (list(m[0][0].children())[8], m[1]) }\n",
    "\n",
    "learn = cnn_learner(data, pnasnet5large, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path = PATH\n",
    "os.system(f\"mv {TRAIN}/models {PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find the learning rate we'll want to use by using Fastai's lr finder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train! After our prototying accuracy seemed to pleateau around 15 epochs, so that's the numbe we'll go with here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(15, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"mv {PATH}/models/{prefix}best.pth {PATH}/models/first_{prefix}best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "learn.load(f\"first_{prefix}best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(30, slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"mv {PATH}/models/{prefix}best.pth {PATH}/models/second_{prefix}best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "learn.load(f\"second_{prefix}best\");\n",
    "learn.data = get_data(256,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(15, slice(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"mv {PATH}/models/{prefix}best.pth {PATH}/models/third_{prefix}best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "learn.load(f\"third_{prefix}best\");\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(15, slice(1e-6, 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"mv {PATH}/models/{prefix}best.pth {PATH}/models/fourth_{prefix}best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ~95% validation accuracy, we were satisfied with our model. Now to get predictions for our test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we looked at image file names and breed types, we need to write a function that changes the category we're looking at to `breedID` instead. First we'll make an infrence learner to get the predictions of the test set images, then feed our results into a pandas dataframe which will be exported into a csv for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_df = pd.read_csv(PATH/'sampleSubmission_breed.csv')\n",
    "samp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting predictions for test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create infrence learner\n",
    "# learn = cnn_learner(data, model, metrics=(error_rate,accuracy))\n",
    "\n",
    "# # xception\n",
    "# learn = cnn_learner(data, model, pretrained=True, cut=-1,\n",
    "#                     split_on=lambda m: (m[0][11], m[1]), metrics=(error_rate,accuracy))\n",
    "\n",
    "# inceptionv4\n",
    "learn = cnn_learner(data, inceptionv4, pretrained=True,\n",
    "                   cut=-2, split_on=lambda m: (m[0][11], m[1]), metrics=(error_rate,accuracy))\n",
    "\n",
    "learn.path = PATH\n",
    "os.system(f\"mv {TRAIN}/models {PATH}\")\n",
    "os.system(f\"mv {LARGE}/models {PATH}\")\n",
    "\n",
    "# Load best model\n",
    "# learn.load(f\"final_{prefix}best\");\n",
    "learn.load(f\"fourth_{prefix}best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Submission Dataframe\n",
    "samp_data = {'fname':[], 'breedID':[]}\n",
    "sub_df = pd.DataFrame(samp_data)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "count = 0\n",
    "dataset = TEST\n",
    "\n",
    "for image in os.listdir(TEST):    \n",
    "    # File names\n",
    "    fname = image[:-4]\n",
    "    \n",
    "    # breed_id predictions\n",
    "    img = open_image(str(TEST/image))\n",
    "    breed_pred = learn.predict(img)[0]\n",
    "    temp_df = train_df.loc[train_df['breed_name'] == f\"{breed_pred}\"]\n",
    "    id_pred = temp_df.values[0][0]\n",
    "    \n",
    "    temp_data = {'fname':[fname], 'breedID':[id_pred]}\n",
    "    temp_sub_df = pd.DataFrame(samp_data)   \n",
    "    sub_df.loc[count] = [fname, id_pred]\n",
    "    \n",
    "    if count%250 == 0:\n",
    "        print(f\"{count} of {len(os.listdir(TEST))} done.\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.sort_values(by=[\"fname\"], inplace=True)\n",
    "sub_df.reset_index(inplace=True)\n",
    "sub_df.drop([\"index\"], axis=1, inplace=True)\n",
    "sub_df[\"breedID\"] = sub_df[\"breedID\"].apply(int)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(f'{PATH}/submissions/{prefix}submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We'll also export our model so we can use it in our Web App:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now create a master submission from using the predictions from multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = Path(PATH/'submissions')\n",
    "sub_list = list(SUB.ls())\n",
    "sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list.pop(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = []\n",
    "for index in range(len(sub_list)):\n",
    "    submissions.append(pd.read_csv(sub_list[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_len = len(pd.read_csv(SUB.ls()[0]))\n",
    "breed_preds = []\n",
    "for row in range(sub_len):\n",
    "    temp_breed_pred = []\n",
    "    \n",
    "    for sub in submissions:\n",
    "        temp_breed_pred.append(sub[\"breedID\"][row])\n",
    "    \n",
    "    # Get mode of predictions\n",
    "    mode = max(set(temp_breed_pred), key=temp_breed_pred.count)\n",
    "    breed_preds.append(mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = list(pd.read_csv(SUB.ls()[0])[\"fname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = {'fname':fnames, 'breedID':breed_preds}\n",
    "final_sub = pd.DataFrame(final_data)\n",
    "final_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub.to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are several images that our model had the most trouble on. If we had more time to work on this project, we'd adjust our training datset accordingly so that we generate more augmented images of each class which should help eliminate some of these losses. We can also see what features activated the model the most, and take that into consideration for future edits of this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the confusion matrix below, we can see a vizualization of the model's performance on all the breeds. The more linear and darker the line from the top right to bottom left is, the more accurate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at what the model was most unsure about, meaning the activations for all the classes we were looking at were all about even, and the model couldn't decide on one that stood out more from the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = Path(PATH/'categories'/'downloads'/'bear -brown -black').ls()\n",
    "TEST[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_image(TEST[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Google Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_images_download import google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GI_PATH = Path(PATH/'gi_train')\n",
    "GI_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_df = train_df[train_df[\"speciesID\"] == 1]\n",
    "cat_breeds = list(cats_df.breed_name.unique())\n",
    "\n",
    "dogs_df = train_df[train_df[\"speciesID\"] == 2]\n",
    "dog_breeds = list(dogs_df.breed_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ids = {}\n",
    "dog_ids = {}\n",
    "\n",
    "for breed in cat_breeds:\n",
    "    temp = train_df[train_df[\"breed_name\"] == breed]\n",
    "    breed_id = list(temp[\"breedID\"])[0]    \n",
    "    breed_name = breed\n",
    "    cat_ids[breed_name] = breed_id\n",
    "    \n",
    "for breed in dog_breeds:\n",
    "    temp = train_df[train_df[\"breed_name\"] == breed]\n",
    "    breed_id = list(temp[\"breedID\"])[0]    \n",
    "    breed_name = breed\n",
    "    dog_ids[breed_name] = breed_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = \"/home/waydegg/Downloads/chromedriver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gi_keywords = []\n",
    "breeds = [dog_breeds, cat_breeds]\n",
    "\n",
    "def download_animal_breeds():\n",
    "    for breed in breeds:\n",
    "        animal = \"\"\n",
    "        if breed == dog_breeds:\n",
    "            animal = \"dog\"\n",
    "        else:\n",
    "            animal = \"cat\"\n",
    "\n",
    "        for sub_breed in breed:\n",
    "            keyword = \"\"\n",
    "            keyword = f\"{animal} {sub_breed}\"\n",
    "\n",
    "            # Exclude breeds in search\n",
    "            for exclude in breed:\n",
    "                if exclude != sub_breed:\n",
    "                    formatted = exclude.replace(\" \", \"_\")\n",
    "                    keyword = keyword + f\" -{formatted}\" \n",
    "\n",
    "            gi_keywords.append(keyword)\n",
    "\n",
    "    for keyword in gi_keywords:\n",
    "        fn = keyword.split(\"-\")[0][4:-1].replace(\" \", \"_\")\n",
    "        KW_PATH = Path(GI_PATH/fn)\n",
    "        KW_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "        os.system(f'googleimagesdownload -k \"{keyword}\" -o {GI_PATH} -i {fn} -l 100 --chromedriver {chrome_driver_path}')\n",
    "        print(f\"Finished downloading {fn} pictures!\")\n",
    "        \n",
    "# download_animal_breeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Image Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiba_inu\n",
      "scottish_terrier\n",
      "Bengal\n",
      "Birman\n",
      "miniature_pinscher\n",
      "beagle\n",
      "Bombay\n",
      "Russian_Blue\n",
      "yorkshire_terrier\n",
      "great_pyrenees\n",
      "newfoundland\n",
      "Egyptian_Mau\n",
      "staffordshire_bull_terrier\n",
      "keeshond\n",
      "British_Shorthair\n",
      "Maine_Coon\n",
      "leonberger\n",
      "chihuahua\n",
      "english_cocker_spaniel\n",
      "japanese_chin\n",
      "wheaten_terrier\n",
      "american_bulldog\n",
      "Siamese\n",
      "american_pit_bull_terrier\n",
      "boxer\n",
      "german_shorthaired\n",
      "havanese\n",
      "pug\n",
      "english_setter\n",
      "Abyssinian\n",
      "Sphynx\n",
      "Persian\n",
      "Ragdoll\n",
      "pomeranian\n",
      "saint_bernard\n",
      "basset_hound\n",
      "samoyed\n",
      "CPU times: user 303 ms, sys: 40.8 s, total: 41.1 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for breed in GI_PATH.ls():\n",
    "    index = 0\n",
    "    breed_name = str(breed).split(\"/\")[-1]\n",
    "    \n",
    "    for animal in breed.ls():\n",
    "        old_fn = str(animal).split(\"/\")[-1]\n",
    "        new_fn = old_fn.replace(\" \", \"\")\n",
    "        suffix = new_fn.split('.')[-1]\n",
    "        new_fn = f\"{breed_name}_{index}.{suffix}\"\n",
    "        old_fn = old_fn.replace(\" \", \"\\ \")\n",
    "        \n",
    "        os.system(f\"mv {breed}/{old_fn} {breed}/{new_fn}\")\n",
    "        index += 1\n",
    "    \n",
    "    print(breed_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label and move downloaded images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINED_TRAIN = Path(PATH/'combined_train')\n",
    "COMBINED_TRAIN.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"breedID\", \"speciesID\", \"fname\", \"breed_name\"]\n",
    "download_df = pd.DataFrame(columns=cols)\n",
    "download_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for breed in GI_PATH.ls():\n",
    "#     verify_images(breed, delete=True)\n",
    "\n",
    "    breed = Path(breed)\n",
    "    index = 0\n",
    "\n",
    "    temp_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for animal in breed.ls():\n",
    "        filename = str(animal).split('/')[-1]\n",
    "        breed = str(animal).split('/')[-2].replace(\"_\", \" \")\n",
    "        breed_id = 0\n",
    "\n",
    "        if filename.split(\".\")[-1] == \"png\" or \"jpg\":\n",
    "            try:\n",
    "                temp_id = dog_ids[breed]\n",
    "                breed_id = 2\n",
    "            except:\n",
    "                temp_id = cat_ids[breed]\n",
    "                breed_id = 1\n",
    "\n",
    "            temp_df.loc[index] = [temp_id, breed_id, filename, breed]\n",
    "            index += 1\n",
    "        else:\n",
    "            print(filename)\n",
    "            os.system(f\"rm {str(animal)}\")\n",
    "        \n",
    "#     break\n",
    "\n",
    "    download_df = download_df.append(temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move images into combined folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_downloaded_images():\n",
    "    # Copying downloaded images\n",
    "    for breed in GI_PATH.ls():\n",
    "        breed_name = str(breed).split(\"/\")[-1]\n",
    "        index = 0\n",
    "        for pic in breed.ls():\n",
    "            print(pic)\n",
    "            \n",
    "            os.system(f\"cp {pic} {COMBINED_TRAIN}\")\n",
    "            index += 1\n",
    "            break\n",
    "        break\n",
    "            \n",
    "#         os.system(f\"cp {breed}/*.jpg {COMBINED_TRAIN}\")\n",
    "#         os.system(f\"cp {breed}/*.png {COMBINED_TRAIN}\")\n",
    "        \n",
    "    # Copying default images\n",
    "#     os.system(f\"cp {PATH}/train/* {COMBINED_TRAIN}\")\n",
    "    \n",
    "move_downloaded_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_df.shape, len(COMBINED_TRAIN.ls()) # These should be the same size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_df[\"fname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_df[download_df[\"fname\"] not in COMBINED_TRAIN.ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
